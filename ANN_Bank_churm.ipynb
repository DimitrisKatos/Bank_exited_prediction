{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 65711,
          "databundleVersionId": 7405009,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "ANN_Bank_churm",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F65711%2F7405009%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240502%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240502T160442Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D05eeea776e858a464fd73fb4884ab89cc17e0bb028d004f108791a11900a60327408eae5b25f48fdc1e14817799775b515e24629d764ee254d1160f97132f954b9a4047cc382cbf252597d4039cfc9baf4797c7d6af624a8faa90216049b69ae3f90c6f4499527a59d58308b2678bc6ad8253751ace71b6a8d156c9265c30cb6a9d60056d5811abfa30becbb9ee17f2e05b0bdff1cee0897eb1d040a3714c6db34ce87300018cf62994bb54d9932e23541ae0a245b451c7898d93e8fec9d0c26c749de19cfa6b968707d6c81f0b3bddf97643deca56e196bba4baa12d3094541c0cb0f49c1db9a32bc7157971d162c2a14d7c783ff0c115a5540046b7ba9534f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "TRunXssaDQcU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer,make_column_selector\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:24.627424Z",
          "iopub.execute_input": "2024-05-01T17:04:24.627856Z",
          "iopub.status.idle": "2024-05-01T17:04:44.11693Z",
          "shell.execute_reply.started": "2024-05-01T17:04:24.627819Z",
          "shell.execute_reply": "2024-05-01T17:04:44.115839Z"
        },
        "trusted": true,
        "id": "i7JFBkW6DQcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/playground-series-s4e1/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/playground-series-s4e1/test.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:44.118834Z",
          "iopub.execute_input": "2024-05-01T17:04:44.119508Z",
          "iopub.status.idle": "2024-05-01T17:04:45.000898Z",
          "shell.execute_reply.started": "2024-05-01T17:04:44.119468Z",
          "shell.execute_reply": "2024-05-01T17:04:44.999573Z"
        },
        "trusted": true,
        "id": "-zzuknW7DQca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanatory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "jZwNrst9DQca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for missing values or Duplicates values."
      ],
      "metadata": {
        "id": "vKNGdsu4DQcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df.duplicated()\n",
        "\n",
        "# Check for duplicated values\n",
        "if duplicates.empty:\n",
        "    print(\"We have duplicates so we drop them.\")\n",
        "    # Drop duplicates values.\n",
        "    df.drop_duplicates(inplace = True)\n",
        "else:\n",
        "    print(\"We don't have duplicates.\")\n",
        "\n",
        "# Check for missing values.\n",
        "if df.isna().any().any():\n",
        "    print(\"We have missing values\")\n",
        "else:\n",
        "    print(\"We don't have missing values!!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:45.002355Z",
          "iopub.execute_input": "2024-05-01T17:04:45.00286Z",
          "iopub.status.idle": "2024-05-01T17:04:45.178035Z",
          "shell.execute_reply.started": "2024-05-01T17:04:45.002816Z",
          "shell.execute_reply": "2024-05-01T17:04:45.176746Z"
        },
        "trusted": true,
        "id": "bTjwchtoDQcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the data types of the dataset."
      ],
      "metadata": {
        "id": "-iK1bJpmDQcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:45.181449Z",
          "iopub.execute_input": "2024-05-01T17:04:45.182395Z",
          "iopub.status.idle": "2024-05-01T17:04:45.190936Z",
          "shell.execute_reply.started": "2024-05-01T17:04:45.18236Z",
          "shell.execute_reply": "2024-05-01T17:04:45.189744Z"
        },
        "trusted": true,
        "id": "kVkhQZ4iDQcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change the data type of some columns"
      ],
      "metadata": {
        "id": "Ml9Ls9J4DQcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of column who want to convert to categorical.\n",
        "categorical_columns = ['Geography','Gender','NumOfProducts','HasCrCard','IsActiveMember','Tenure']\n",
        "\n",
        "# Our target category.\n",
        "target = 'Exited'\n",
        "df[target] = df[target].astype('str')\n",
        "\n",
        "# Convert to categorical.\n",
        "for column in categorical_columns:\n",
        "    df[column] = df[column].astype('str')\n",
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:45.192424Z",
          "iopub.execute_input": "2024-05-01T17:04:45.192878Z",
          "iopub.status.idle": "2024-05-01T17:04:45.896937Z",
          "shell.execute_reply.started": "2024-05-01T17:04:45.192837Z",
          "shell.execute_reply": "2024-05-01T17:04:45.895731Z"
        },
        "trusted": true,
        "id": "igpNMFcXDQcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Return some statistics for the categorical data.\n",
        "### From the above results we can see some unpredictable statistics that we must check through our analysis.\n",
        "### We must check the data distribution on the following columns:\n",
        "- Age,\n",
        "- Balance\n",
        "- EstimateSalary"
      ],
      "metadata": {
        "id": "DmnbNpeKDQce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:45.898494Z",
          "iopub.execute_input": "2024-05-01T17:04:45.898977Z",
          "iopub.status.idle": "2024-05-01T17:04:45.968369Z",
          "shell.execute_reply.started": "2024-05-01T17:04:45.898935Z",
          "shell.execute_reply": "2024-05-01T17:04:45.967181Z"
        },
        "trusted": true,
        "id": "ZhJT5J-0DQce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Data"
      ],
      "metadata": {
        "id": "iJnLwVuBDQce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Age Distribution."
      ],
      "metadata": {
        "id": "O-IKIMb0DQce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distibution of the Age columns.\n",
        "sns.histplot(data = df, x ='Age',bins = 20,color='green',edgecolor='black',kde=True)\n",
        "\n",
        "# Calculate mean and median\n",
        "mean_value = df[\"Age\"].mean()\n",
        "median_value = df[\"Age\"].median()\n",
        "\n",
        "# Add mean and median lines\n",
        "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_value:.2f}')\n",
        "plt.axvline(median_value, color='blue', linestyle='dashed', linewidth=2, label=f'Median: {median_value:.2f}')\n",
        "\n",
        "# Rename the axis.\n",
        "plt.title(\"Distribution of Age.\")\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:45.969748Z",
          "iopub.execute_input": "2024-05-01T17:04:45.970086Z",
          "iopub.status.idle": "2024-05-01T17:04:47.26357Z",
          "shell.execute_reply.started": "2024-05-01T17:04:45.970058Z",
          "shell.execute_reply": "2024-05-01T17:04:47.262423Z"
        },
        "trusted": true,
        "id": "TqUDxsNEDQce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of the Balance column."
      ],
      "metadata": {
        "id": "gjg1gvLlDQce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distibution of the Age columns.\n",
        "sns.histplot(data = df, x ='Balance',bins = 20,color='green',edgecolor='#26090b',kde=True)\n",
        "\n",
        "# Calculate mean and median\n",
        "mean_value = df[\"Balance\"].mean()\n",
        "median_value = df[\"Balance\"].median()\n",
        "\n",
        "# Add mean and median lines\n",
        "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_value:.2f}')\n",
        "plt.axvline(median_value, color='blue', linestyle='dashed', linewidth=2, label=f'Median: {median_value:.2f}')\n",
        "\n",
        "# Rename the axis.\n",
        "plt.title(\"Distribution of BalanceBalance.\")\n",
        "plt.xlabel('Balance')\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:47.265283Z",
          "iopub.execute_input": "2024-05-01T17:04:47.266104Z",
          "iopub.status.idle": "2024-05-01T17:04:48.527348Z",
          "shell.execute_reply.started": "2024-05-01T17:04:47.266062Z",
          "shell.execute_reply": "2024-05-01T17:04:48.5259Z"
        },
        "trusted": true,
        "id": "p6tClsteDQce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of the Estimated Salary"
      ],
      "metadata": {
        "id": "o-JWVYqJDQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distibution of the Age columns.\n",
        "sns.histplot(data = df, x ='EstimatedSalary',bins = 20,color='green',edgecolor='#26090b',kde=True)\n",
        "\n",
        "# Calculate mean and median\n",
        "mean_value = df[\"EstimatedSalary\"].mean()\n",
        "median_value = df[\"EstimatedSalary\"].median()\n",
        "\n",
        "# Add mean and median lines\n",
        "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_value:.2f}')\n",
        "plt.axvline(median_value, color='blue', linestyle='dashed', linewidth=2, label=f'Median: {median_value:.2f}')\n",
        "\n",
        "# Rename the axis.\n",
        "plt.title(\"Distribution of EstimatedSalary.\")\n",
        "plt.xlabel('EstimatedSalary')\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:48.528859Z",
          "iopub.execute_input": "2024-05-01T17:04:48.529231Z",
          "iopub.status.idle": "2024-05-01T17:04:49.739149Z",
          "shell.execute_reply.started": "2024-05-01T17:04:48.529198Z",
          "shell.execute_reply": "2024-05-01T17:04:49.737929Z"
        },
        "trusted": true,
        "id": "v7dmt2-gDQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(14, len(categorical_columns)*3))\n",
        "\n",
        "# background_color = 'grey'\n",
        "for i, col in enumerate(categorical_columns):\n",
        "\n",
        "    plt.subplot(len(categorical_columns)//2 + len(categorical_columns) % 2, 2, i+1)\n",
        "    sns.countplot(x=col, hue=target, data=df,)\n",
        "    plt.title(f\"{col} countplot by target\", fontweight = 'bold')\n",
        "    plt.ylim(0, df[col].value_counts().max() + 10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:49.744707Z",
          "iopub.execute_input": "2024-05-01T17:04:49.745106Z",
          "iopub.status.idle": "2024-05-01T17:04:53.956274Z",
          "shell.execute_reply.started": "2024-05-01T17:04:49.745072Z",
          "shell.execute_reply": "2024-05-01T17:04:53.955078Z"
        },
        "trusted": true,
        "id": "H1EZVSw6DQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a new dataset, and  drop id, CustomerId and SurnName"
      ],
      "metadata": {
        "id": "euAq8hS0DQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df.drop(['id','CustomerId','Surname'], axis = 1)\n",
        "dataset.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:53.957691Z",
          "iopub.execute_input": "2024-05-01T17:04:53.958067Z",
          "iopub.status.idle": "2024-05-01T17:04:53.998743Z",
          "shell.execute_reply.started": "2024-05-01T17:04:53.958037Z",
          "shell.execute_reply": "2024-05-01T17:04:53.997544Z"
        },
        "trusted": true,
        "id": "oR-B8a7eDQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:54.000659Z",
          "iopub.execute_input": "2024-05-01T17:04:54.001143Z",
          "iopub.status.idle": "2024-05-01T17:04:54.161555Z",
          "shell.execute_reply.started": "2024-05-01T17:04:54.001101Z",
          "shell.execute_reply": "2024-05-01T17:04:54.160444Z"
        },
        "trusted": true,
        "id": "NP51g8qCDQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Heatmap.\n",
        "### From the following heatmap we can easily said that the most correlated columns is Gender, Age, Balance and IsActiveMember.\n",
        "### For the other columns, we must apply logistic regression or correaltion test to see if it statistically significant."
      ],
      "metadata": {
        "id": "V4lEJiMtDQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catcol = [col for col in dataset.columns if dataset[col].dtype == \"object\"]\n",
        "le = LabelEncoder()\n",
        "for col in catcol:\n",
        "        dataset[col] = le.fit_transform(dataset[col])\n",
        "\n",
        "\n",
        "plt.subplots(figsize =(10, 10))\n",
        "\n",
        "sns.heatmap(dataset.corr(), square=True, cbar_kws=dict(shrink =.82),\n",
        "            annot=True, vmin=-1, vmax=1, linewidths=3,linecolor='#e0b583',annot_kws=dict(fontsize =12))\n",
        "plt.title(\"Pearson Correlation Of Features\\n\", fontsize=25)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:54.162877Z",
          "iopub.execute_input": "2024-05-01T17:04:54.163219Z",
          "iopub.status.idle": "2024-05-01T17:04:55.403511Z",
          "shell.execute_reply.started": "2024-05-01T17:04:54.163189Z",
          "shell.execute_reply": "2024-05-01T17:04:55.402324Z"
        },
        "trusted": true,
        "id": "nsZb5x5eDQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We have to apply a test to see if some columns are statistically significant\n",
        "### You can use anova test or logistic regressor."
      ],
      "metadata": {
        "id": "aFKKOOwmDQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column to check\n",
        "columns_to_check = ['CreditScore','EstimatedSalary','HasCrCard','Tenure','Geography','CreditScore']\n",
        "\n",
        "# Anova test\n",
        "for column in columns_to_check:\n",
        "    # Fit an Ordinary Least Squares (OLS) model\n",
        "    formula = f'Exited ~ {column}'\n",
        "    model = ols(formula, data=dataset).fit()\n",
        "\n",
        "    # Perform ANOVA\n",
        "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    print(f\"ANOVA results for {column}:\")\n",
        "    print(anova_table)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:55.405442Z",
          "iopub.execute_input": "2024-05-01T17:04:55.40589Z",
          "iopub.status.idle": "2024-05-01T17:04:55.982801Z",
          "shell.execute_reply.started": "2024-05-01T17:04:55.405849Z",
          "shell.execute_reply": "2024-05-01T17:04:55.981599Z"
        },
        "trusted": true,
        "id": "TyxaFbNLDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression model.\n",
        "for column in columns_to_check:\n",
        "    # Add a constant term to the predictors\n",
        "    predictors = sm.add_constant(dataset[column])\n",
        "\n",
        "    # Fit logistic regression model\n",
        "    logit_model = sm.Logit(dataset['Exited'], predictors)\n",
        "    result = logit_model.fit()\n",
        "\n",
        "    # Print summary of the logistic regression model\n",
        "    print(f\"Logistic regression results for {column}:\")\n",
        "    print(result.summary())\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:04:55.984233Z",
          "iopub.execute_input": "2024-05-01T17:04:55.984985Z",
          "iopub.status.idle": "2024-05-01T17:05:01.887582Z",
          "shell.execute_reply.started": "2024-05-01T17:04:55.984944Z",
          "shell.execute_reply": "2024-05-01T17:05:01.886408Z"
        },
        "trusted": true,
        "id": "tCHajNbFDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All the p-values are close to zero, so this columns is statistical significant with the target variable."
      ],
      "metadata": {
        "id": "9kS_Fn_wDQcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['id','CustomerId','Surname'], axis = 1,inplace = True)\n",
        "df[target] = df[target].astype('int')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:05:01.889316Z",
          "iopub.execute_input": "2024-05-01T17:05:01.890033Z",
          "iopub.status.idle": "2024-05-01T17:05:01.998105Z",
          "shell.execute_reply.started": "2024-05-01T17:05:01.889991Z",
          "shell.execute_reply": "2024-05-01T17:05:01.996916Z"
        },
        "trusted": true,
        "id": "M_RC76SxDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:05:02.000865Z",
          "iopub.execute_input": "2024-05-01T17:05:02.001595Z",
          "iopub.status.idle": "2024-05-01T17:05:02.124067Z",
          "shell.execute_reply.started": "2024-05-01T17:05:02.001551Z",
          "shell.execute_reply": "2024-05-01T17:05:02.122962Z"
        },
        "trusted": true,
        "id": "9_PHpPFlDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for modeling\n"
      ],
      "metadata": {
        "id": "wjKsaGOpDQcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent and Independent variable.\n",
        "X = df.drop(['Exited'],axis = 1)\n",
        "y = df['Exited']\n",
        "\n",
        "# Split the dataset.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.75, random_state = 42)\n",
        "\n",
        "# Create a transformation\n",
        "transformer = ColumnTransformer([\n",
        "    ('categorical_encoding', OneHotEncoder(sparse = False, drop ='if_binary'),make_column_selector(dtype_include='object')) ,\n",
        "    ('numerical_transformation', StandardScaler(),make_column_selector(dtype_exclude='object'))\n",
        "])\n",
        "\n",
        "# Apply transformation\n",
        "X_train_scaled = transformer.fit_transform(X_train)\n",
        "X_test_scaled = transformer.transform(X_test)\n",
        "\n",
        "# Get the name of new columns.\n",
        "new_categorical_column_names = transformer.named_transformers_['categorical_encoding'] \\\n",
        "                                 .get_feature_names_out()\n",
        "\n",
        "# Get the names of the numerical columns (which remain the same after transformation)\n",
        "numerical_column_names = transformer.transformers_[1][2]\n",
        "\n",
        "# Concatenate the new column names\n",
        "new_column_names = list(new_categorical_column_names) + list(numerical_column_names)\n",
        "\n",
        "# Create a DataFrame with the transformed data and new column names\n",
        "transformed_df = pd.DataFrame(X_train_scaled, columns=new_column_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:06:40.960869Z",
          "iopub.execute_input": "2024-05-01T17:06:40.961303Z",
          "iopub.status.idle": "2024-05-01T17:06:41.95077Z",
          "shell.execute_reply.started": "2024-05-01T17:06:40.961273Z",
          "shell.execute_reply": "2024-05-01T17:06:41.949658Z"
        },
        "trusted": true,
        "id": "Ltj0sUnFDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train the Random Forest Classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict using the trained classifier\n",
        "y_pred = random_forest.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:06:49.939562Z",
          "iopub.execute_input": "2024-05-01T17:06:49.940614Z",
          "iopub.status.idle": "2024-05-01T17:07:17.291158Z",
          "shell.execute_reply.started": "2024-05-01T17:06:49.940577Z",
          "shell.execute_reply": "2024-05-01T17:07:17.289908Z"
        },
        "trusted": true,
        "id": "L0D9gQGiDQcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an Artificial Neural Network"
      ],
      "metadata": {
        "id": "MeBryt6pDQch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units = 6, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 12, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 12, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 6, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "ann.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "ann.fit(X_train_scaled,y_train, batch_size = 128 ,epochs = 30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:25:45.893647Z",
          "iopub.execute_input": "2024-05-01T17:25:45.894988Z",
          "iopub.status.idle": "2024-05-01T17:26:40.086733Z",
          "shell.execute_reply.started": "2024-05-01T17:25:45.89494Z",
          "shell.execute_reply": "2024-05-01T17:26:40.08525Z"
        },
        "trusted": true,
        "id": "P_7a24qiDQch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to categorical.\n",
        "for column in categorical_columns:\n",
        "    test_df[column] = test_df[column].astype('str')\n",
        "test_df.info()\n",
        "\n",
        "# Scaled test data\n",
        "X_submission_scaled = transformer.transform(test_df)\n",
        "predictions = ann.predict(X_submission_scaled)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:32:58.767917Z",
          "iopub.execute_input": "2024-05-01T17:32:58.768886Z",
          "iopub.status.idle": "2024-05-01T17:33:05.483844Z",
          "shell.execute_reply.started": "2024-05-01T17:32:58.76884Z",
          "shell.execute_reply": "2024-05-01T17:33:05.482562Z"
        },
        "trusted": true,
        "id": "BcfusVZGDQch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/kaggle/input/playground-series-s4e1/sample_submission.csv')\n",
        "df_submission['Exited']=predictions\n",
        "df_submission.to_csv(\"submission.csv\", index=False)\n",
        "df_submission.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T17:33:21.192575Z",
          "iopub.execute_input": "2024-05-01T17:33:21.193039Z",
          "iopub.status.idle": "2024-05-01T17:33:21.530788Z",
          "shell.execute_reply.started": "2024-05-01T17:33:21.193005Z",
          "shell.execute_reply": "2024-05-01T17:33:21.529604Z"
        },
        "trusted": true,
        "id": "fXMMgH6LDQch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81eTc3vODQch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}